{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tkinter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from UtilityFunctions import *\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models_svm():\n",
    "\n",
    "    model_c1_svm = pickle.load(open('h_models_svm/model_c1.sav', 'rb'))\n",
    "    model_c2_svm = pickle.load(open('h_models_svm/model_c2.sav', 'rb'))\n",
    "    model_c3_svm = pickle.load(open('h_models_svm/model_c3.sav', 'rb'))\n",
    "    \n",
    "    return model_c1_svm, model_c2_svm, model_c3_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models_rnn():\n",
    "    \n",
    "    model_c1_rnn=tf.keras.models.load_model('h_models_rnn/model_c1/0.922')\n",
    "    model_c2_rnn=tf.keras.models.load_model('h_models_rnn/model_c2/0.881')\n",
    "    model_c3_rnn=tf.keras.models.load_model('h_models_rnn/model_c3/0.800')\n",
    "    \n",
    "    return model_c1_rnn, model_c2_rnn, model_c3_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_pred_query(query):\n",
    "\n",
    "    corpus_vocabulary = defaultdict(None, copy.deepcopy(tfidf_vectorizer.vocabulary_))\n",
    "    corpus_vocabulary.default_factory = corpus_vocabulary.__len__\n",
    "\n",
    "    tfidf_transformer_query = TfidfVectorizer()\n",
    "    tfidf_transformer_query.fit_transform([query])\n",
    "\n",
    "    for word in tfidf_transformer_query.vocabulary_.keys():\n",
    "        if word in tfidf_vectorizer.vocabulary_:\n",
    "            corpus_vocabulary[word]\n",
    "\n",
    "    tfidf_transformer_query_sec = TfidfVectorizer(vocabulary=corpus_vocabulary)\n",
    "    query_tfidf_matrix = tfidf_transformer_query_sec.fit_transform([query])\n",
    "    \n",
    "    return model_c1_svm.predict(query_tfidf_matrix), model_c2_svm.predict(query_tfidf_matrix), model_c3_svm.predict(query_tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_pred_query(query_df):\n",
    "    token = RegexpTokenizer(\"[\\w']+\")\n",
    "    maxWords = 20000\n",
    "    MaxWordLength = train_df.title.map(lambda x: len(token.tokenize(x))).max()\n",
    "    tokenizer = Tokenizer(num_words = maxWords, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "    tokenizer.fit_on_texts(train_df['title'].values)\n",
    "\n",
    "    cat = []\n",
    "\n",
    "    seq = tokenizer.texts_to_sequences((query_df['title']).values)\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(seq, maxlen=MaxWordLength)\n",
    "\n",
    "    pred1 = model_c1_rnn.predict(padded)\n",
    "    cat.append(labels_c1[np.argmax(pred1)])\n",
    "\n",
    "    query_df['title'] = query_df['title'] + ' ' + labels_c1[np.argmax(pred1)]\n",
    "\n",
    "    seq = tokenizer.texts_to_sequences((query_df['title']).values)\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(seq, maxlen=MaxWordLength)\n",
    "\n",
    "    pred2 = model_c2_rnn.predict(padded)\n",
    "    cat.append(labels_c2[np.argmax(pred2)])\n",
    "\n",
    "    query_df['title'] = query_df['title'] +' '+ labels_c2[np.argmax(pred2)]\n",
    "\n",
    "    seq = tokenizer.texts_to_sequences((query_df['title']).values)\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(seq, maxlen=MaxWordLength)\n",
    "\n",
    "    pred3 = model_c3_rnn.predict(padded)\n",
    "    cat.append(labels_c3[np.argmax(pred3)])\n",
    "    \n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_window():\n",
    "\n",
    "    def find_cat():\n",
    "        svm_textbar.delete(\"1.0\",tkinter.END)\n",
    "        rnn_textbar.delete(\"1.0\",tkinter.END)\n",
    "        \n",
    "        title = title_entry.get()\n",
    "        desc = desc_entry.get()\n",
    "        \n",
    "        data = {'title':[title],\n",
    "                'description':[desc]}\n",
    "        \n",
    "        query_df = pd.DataFrame(data)\n",
    "        PreProcess(query_df)\n",
    "\n",
    "        query = str(query_df['title'].values+' '+query_df['description'].values)\n",
    "        query_df['title'] = query_df['title'] + ' ' + query_df['description']\n",
    "        query_df = query_df.drop(['description'], axis=1)\n",
    "\n",
    "        svm_pred = svm_pred_query(query)\n",
    "        svm_pred = [p[0] for p in svm_pred]\n",
    "        svm = ''\n",
    "        svm += 'Category 1: '+ svm_pred[0] + '\\nCategory 2: ' + svm_pred[1] + '\\nCategory 3: ' + svm_pred[2]\n",
    "        svm_textbar.insert(tkinter.INSERT, svm)\n",
    "\n",
    "        rnn_pred = rnn_pred_query(query_df)\n",
    "        rnn = ''\n",
    "        rnn += 'Category 1: '+ rnn_pred[0] + '\\nCategory 2: ' + rnn_pred[1] + '\\nCategory 3: ' + rnn_pred[2]\n",
    "        rnn_textbar.insert(tkinter.INSERT, rnn)\n",
    "        \n",
    "\n",
    "    window = tkinter.Tk()\n",
    "    window.title('')\n",
    "    window.config(bg='PeachPuff2')\n",
    "    width = 1000\n",
    "    height = 600\n",
    "    screen_width = window.winfo_screenwidth()\n",
    "    screen_height = window.winfo_screenheight()\n",
    "    x_cod = (screen_width / 2) - (width / 2)\n",
    "    y_cod = (screen_height / 2) - (height / 2)\n",
    "    window.geometry('%dx%d+%d+%d' % (width, height, x_cod, y_cod))\n",
    "    ptc_label = tkinter.Label(window, text='Product Title Classification', bg='PeachPuff2', fg='black')\n",
    "    ptc_label.config(font=(\"Courier\", 20, 'bold'))\n",
    "    ptc_label.place(x=220, y=40)\n",
    "\n",
    "    mid_label = tkinter.Label(window, text='SVM VS RNN', bg='PeachPuff2', fg='black')\n",
    "    mid_label.config(font=(\"Courier\", 20, 'bold'))\n",
    "    mid_label.place(x=380, y=80)\n",
    "\n",
    "    title_label = tkinter.Label(window, text='Title:', bg='PeachPuff2', fg='black')\n",
    "    title_label.config(font=(\"Courier\", 12))\n",
    "    title_label.place(x=100, y=180)\n",
    "\n",
    "    title_entry = tkinter.Entry(window)\n",
    "    title_entry.pack()\n",
    "    title_entry.place(x=260, y=180,height=25 , width=620)\n",
    "\n",
    "    desc_label = tkinter.Label(window, text='Description:', bg='PeachPuff2', fg='black')\n",
    "    desc_label.config(font=(\"Courier\", 12))\n",
    "    desc_label.place(x=100, y=220)\n",
    "\n",
    "    desc_entry = tkinter.Entry(window)\n",
    "    desc_entry.pack()\n",
    "    desc_entry.place(x=260, y=220,height=25 , width=620)\n",
    "\n",
    "    exe_button = tkinter.Button(window, text=\"Execute\",command=find_cat, bg='white')\n",
    "    exe_button.place(x=470, y=260, height=30, width= 120)\n",
    "    \n",
    "\n",
    "    pred_label = tkinter.Label(window, text='Predicted Categories:', bg='PeachPuff2', fg='black')\n",
    "    pred_label.config(font=(\"Courier\", 12))\n",
    "    pred_label.place(x=100, y=300)\n",
    "\n",
    "    svm_label = tkinter.Label(window, text='SVM', bg='PeachPuff2', fg='black')\n",
    "    svm_label.config(font=(\"Courier\", 12))\n",
    "    svm_label.place(x=250, y=360)\n",
    "\n",
    "    rnn_label = tkinter.Label(window, text='RNN', bg='PeachPuff2', fg='black')\n",
    "    rnn_label.config(font=(\"Courier\", 12))\n",
    "    rnn_label.place(x=680, y=360)\n",
    "\n",
    "    svm_textbar = tkinter.Text(window)\n",
    "    svm_textbar.pack()\n",
    "    svm_textbar.place(x=100, y=400,height=120 , width=350)\n",
    "\n",
    "    rnn_textbar = tkinter.Text(window)\n",
    "    rnn_textbar.pack()\n",
    "    rnn_textbar.place(x=530, y=400,height=120 , width=350)\n",
    "\n",
    "    window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"clean.csv\")\n",
    "labels_c1=sorted(train_df['c1'].unique())\n",
    "labels_c2=sorted(train_df['c2'].unique())\n",
    "train_df['c3'] = train_df['c3'].replace(np.nan, 'none', regex=True)\n",
    "labels_c3=sorted(train_df['c3'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = pickle.load(open('h_models_svm/tfidf_vectorizer.pickle','rb'))\n",
    "model_c1_svm, model_c2_svm, model_c3_svm = load_models_svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_c1_rnn, model_c2_rnn, model_c3_rnn = load_models_rnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002AFB3E673A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002AFEF511E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
